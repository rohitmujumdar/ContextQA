{"paragraphs": [{"context": "A consequence of biological naturalism is that if we want to create a conscious being, we will have to duplicate whatever physical processes the brain goes through to cause consciousness. Searle thereby means to contradict what he calls \"Strong AI\", defined by the assumption that as soon as a certain kind of software is running on a computer, a conscious being is thereby created. In 1980, Searle presented the \"Chinese room\" argument, which purports to prove the falsity of strong AI. Assume you do not speak Chinese and imagine yourself in a room with two slits, a book, and some scratch paper. Someone slides you some Chinese characters through the first slit, you follow the instructions in the book, transcribing characters as instructed onto the scratch paper, and slide the resulting sheet out the second slit. To people on the outside world, it appears the room speaks Chinese--they slide Chinese statements in one slit and get valid responses in return--yet you do not understand a word of Chinese. This suggests, according to Searle, that no computer can ever understand Chinese or English, because, as the thought experiment suggests, being able to 'translate' Chinese into English does not entail 'understanding' either Chinese or English: all which the person in the thought experiment, and hence a computer, is able to do is to execute certain syntactic manipulations. Stevan Harnad argues that Searle's \"Strong AI\" is really just another name for functionalism and computationalism, and that these positions are the real targets of his critique. Functionalists argue that consciousness can be defined as a set of informational processes inside the brain. It follows that anything that carries out the same informational processes as a human is also conscious. Thus, if we wrote a computer program that was conscious, we could run that computer program on, say, a system of ping-pong balls and beer cups and the system would be equally conscious, because it was running the same information processes. Searle argues that this is impossible, since consciousness is a physical property, like digestion or fire. No matter how good a simulation of digestion you build on the computer, it will not digest anything; no matter how well you simulate fire, nothing will get burnt. By contrast, informational processes are observer-relative: observers pick out certain patterns in the world and consider them information processes, but information processes are not things-in-the-world themselves. Since they do not exist at a physical level, Searle argues, they cannot have causal efficacy and thus cannot cause consciousness. There is no physical law, Searle insists, that can see the equivalence between a personal computer, a series of ping-pong balls and beer cans, and a pipe-and-water system all implementing the same program. CANNOTANSWER", "qas": [{"followup": "y", "yesno": "x", "question": "What was Searles part in Artificial Intelligence", "answers": [{"text": "In 1980, Searle presented the \"Chinese room\" argument, which purports to prove the falsity of strong AI.", "answer_start": 383}, {"text": "Searle thereby means to contradict what he calls \"Strong AI\", defined by the assumption that as soon as a certain kind of software is running on a computer,", "answer_start": 188}, {"text": "Searle presented the \"Chinese room\" argument, which purports to prove the falsity of strong AI.", "answer_start": 392}, {"text": "In 1980, Searle presented the \"Chinese room\" argument, which purports to prove the falsity of strong AI.", "answer_start": 383}, {"text": "In 1980, Searle presented the \"Chinese room\" argument, which purports to prove the falsity of strong AI.", "answer_start": 383}], "id": "C_14c09ece52d34312863135b02007eafd_1_q#0", "orig_answer": {"text": "In 1980, Searle presented the \"Chinese room\" argument, which purports to prove the falsity of strong AI.", "answer_start": 383}}, {"followup": "y", "yesno": "x", "question": "how did it prove it", "answers": [{"text": "which the person in the thought experiment, and hence a computer, is able to do is to execute certain syntactic manipulations.", "answer_start": 1258}, {"text": "being able to 'translate' Chinese into English does not entail 'understanding' either Chinese or English:", "answer_start": 1148}, {"text": "being able to 'translate' Chinese into English does not entail 'understanding' either Chinese or English: all which the person in the thought experiment, and hence a computer,", "answer_start": 1148}, {"text": "Assume you do not speak Chinese and imagine yourself in a room with two slits, a book, and some scratch paper. Someone slides you some Chinese characters", "answer_start": 488}], "id": "C_14c09ece52d34312863135b02007eafd_1_q#1", "orig_answer": {"text": "Assume you do not speak Chinese and imagine yourself in a room with two slits, a book, and some scratch paper. Someone slides you some Chinese characters", "answer_start": 488}}, {"followup": "y", "yesno": "x", "question": "what happens after", "answers": [{"text": "you follow the instructions in the book, transcribing characters as instructed onto the scratch paper, and slide the resulting sheet out the second slit.", "answer_start": 666}, {"text": "all which the person in the thought experiment, and hence a computer, is able to do is to execute certain syntactic manipulations.", "answer_start": 1254}, {"text": "through the first slit, you follow the instructions in the book, transcribing characters as instructed onto the scratch paper, and slide the resulting sheet out the second slit.", "answer_start": 642}, {"text": "we could run that computer program on, say, a system of ping-pong balls and beer cups and the system would be equally conscious, because it was running the same", "answer_start": 1834}, {"text": "you follow the instructions in the book, transcribing characters as instructed onto the scratch paper, and slide the resulting sheet out the second slit. To people on the outside world,", "answer_start": 666}], "id": "C_14c09ece52d34312863135b02007eafd_1_q#2", "orig_answer": {"text": "you follow the instructions in the book, transcribing characters as instructed onto the scratch paper, and slide the resulting sheet out the second slit. To people on the outside world,", "answer_start": 666}}, {"followup": "y", "yesno": "x", "question": "what happens to the outside world", "answers": [{"text": "it appears the room speaks Chinese--they slide Chinese statements in one slit and get valid responses in return--yet you do not understand a word of Chinese.", "answer_start": 852}, {"text": "informational processes are observer-relative: observers pick out certain patterns in the world", "answer_start": 2301}, {"text": "it appears the room speaks Chinese--they slide Chinese statements in one slit and get valid responses in return--yet you do not understand a word of Chinese.", "answer_start": 852}, {"text": "No matter how good a simulation of digestion you build on the computer, it will not digest anything; no matter how well you simulate fire, nothing will get burnt.", "answer_start": 2125}, {"text": "it appears the room speaks Chinese--they slide Chinese statements in one slit and get valid responses in return--yet you do not understand a word of Chinese.", "answer_start": 852}], "id": "C_14c09ece52d34312863135b02007eafd_1_q#3", "orig_answer": {"text": "it appears the room speaks Chinese--they slide Chinese statements in one slit and get valid responses in return--yet you do not understand a word of Chinese.", "answer_start": 852}}, {"followup": "y", "yesno": "y", "question": "So the AI is like getting information from a book without really knowing it", "answers": [{"text": "all which the person in the thought experiment, and hence a computer, is able to do is to execute certain syntactic manipulations.", "answer_start": 1254}, {"text": "There is no physical law, Searle insists, that can see the equivalence between a personal computer,", "answer_start": 2634}, {"text": "This suggests, according to Searle, that no computer can ever understand Chinese or English,", "answer_start": 1010}, {"text": "a computer, is able to do is to execute certain syntactic manipulations.", "answer_start": 1312}, {"text": "according to Searle, that no computer can ever understand Chinese or English, because, as the thought experiment suggests, being able to 'translate' Chinese into English does not entail 'understanding' either", "answer_start": 1025}], "id": "C_14c09ece52d34312863135b02007eafd_1_q#4", "orig_answer": {"text": "according to Searle, that no computer can ever understand Chinese or English, because, as the thought experiment suggests, being able to 'translate' Chinese into English does not entail 'understanding' either", "answer_start": 1025}}, {"followup": "m", "yesno": "x", "question": "what does it entail", "answers": [{"text": "all which the person in the thought experiment, and hence a computer, is able to do is to execute certain syntactic manipulations.", "answer_start": 1254}, {"text": "a series of ping-pong balls and beer cans, and a pipe-and-water system all implementing the same program.", "answer_start": 2734}, {"text": "all which the person in the thought experiment, and hence a computer, is able to do is to execute certain syntactic manipulations.", "answer_start": 1254}, {"text": "does not entail 'understanding' either Chinese or English: all which the person in the thought experiment, and hence a computer, is able to do is to execute certain syntactic manipulations.", "answer_start": 1195}, {"text": "all which the person in the thought experiment, and hence a computer, is able to do is to execute certain syntactic manipulations.", "answer_start": 1254}], "id": "C_14c09ece52d34312863135b02007eafd_1_q#5", "orig_answer": {"text": "all which the person in the thought experiment, and hence a computer, is able to do is to execute certain syntactic manipulations.", "answer_start": 1254}}, {"followup": "y", "yesno": "y", "question": "Are there any other interesting aspects about this article?", "answers": [{"text": "Stevan Harnad argues that Searle's \"Strong AI\" is really just another name for functionalism and computationalism,", "answer_start": 1385}, {"text": "Searle argues that this is impossible, since consciousness is a physical property, like digestion or fire.", "answer_start": 2018}, {"text": "Stevan Harnad argues that Searle's \"Strong AI\" is really just another name for functionalism and computationalism,", "answer_start": 1385}, {"text": "Since they do not exist at a physical level, Searle argues, they cannot have causal efficacy and thus cannot cause consciousness.", "answer_start": 2504}, {"text": "Stevan Harnad argues that Searle's \"Strong AI\" is really just another name for functionalism and computationalism, and that these positions are the real targets of his critique.", "answer_start": 1385}], "id": "C_14c09ece52d34312863135b02007eafd_1_q#6", "orig_answer": {"text": "Stevan Harnad argues that Searle's \"Strong AI\" is really just another name for functionalism and computationalism, and that these positions are the real targets of his critique.", "answer_start": 1385}}], "id": "C_14c09ece52d34312863135b02007eafd_1"}], "section_title": "Artificial intelligence", "background": "John Rogers Searle (; born 31 July 1932) is an American philosopher. He is currently Willis S. and Marion Slusser Professor Emeritus of the Philosophy of Mind and Language and Professor of the Graduate School at the University of California, Berkeley. Widely noted for his contributions to the philosophy of language, philosophy of mind, and social philosophy, he began teaching at UC Berkeley in 1959.", "title": "John Searle"}